# Lama Rawat Predictor — minimal prototype

This workspace contains a minimal full-stack prototype to serve your pickled model (`model.pkl`) and a Vite + React frontend that lets users enter inputs (including human-friendly diagnosis names) and get a prediction for "Lama Rawat" (length of stay in days).

What I added:
- `backend/parse_data.py` — script that parses `Data.txt` and writes `backend/schema.json` with categorical options and diagnosis mappings.
- `backend/schema.json` (generated by `parse_data.py`) will be created when you run the parser.
- `backend/app.py` — FastAPI app that exposes `/schema` and `/predict` endpoints. It loads `backend/model.pkl` if present.
- `backend/requirements.txt` — Python dependencies for the backend.
- `frontend/` — a minimal Vite + React app that fetches `/schema`, builds a form, and calls `/predict`.

Important notes / assumptions
- I assume your model is a scikit-learn compatible estimator (or similar) serialized with `joblib.dump` / `pickle` and that it accepts a pandas DataFrame with column names matching the keys used in the input payload.
- If the model expects specific preprocessing or a fixed feature order, you may need to adapt `backend/app.py` to apply the same preprocessing and column ordering before calling `model.predict`.

How to run (Windows PowerShell)

1) Generate the schema.json from `Data.txt` (this extracts categorical lists and diagnosis mappings):

```powershell
python .\backend\parse_data.py
```

This will write `backend/schema.json`.

2) Put your model file `model.pkl` into `d:\Prediksi_Lama_Rawat\backend\model.pkl`.

3) Create a Python environment and install backend deps, then run the API:

```powershell
py -3 -m venv .venv
. .\.venv\Scripts\Activate.ps1
pip install -r .\backend\requirements.txt
# Start the API on port 8000
uvicorn backend.app:app --reload --host 127.0.0.1 --port 8000
```

4) Start the frontend (in a separate terminal)

```powershell
cd .\frontend
npm install
npm run dev
```

5) Open the frontend at the address printed by Vite (usually http://localhost:5173) and try the form.

What to do if prediction fails
- Check backend logs — if the model raises a shape / column name error, adapt `backend/app.py` to reorder or select columns to match how the model was trained.
- If your model requires preprocessing (scalers, encoders), it's easiest to package the full pipeline into the saved `model.pkl` (e.g., sklearn Pipeline). If not, you need to replicate preprocessing in `app.py`.

Next steps I can help with
- Wire your exact model preprocessing into the backend so predictions match training.
- Add validation and nicer UI/UX (help texts, searchable diagnosis dropdown, autocompletion).
- Package as a single Docker container for easy deployment.
